"""
Vanna AI æœåŠ¡æ¨¡å— - åŸºäº Vanna 2.0 + é€šä¹‰åƒé—®çš„ Text-to-SQL
ç¬¦åˆæŠ€æœ¯æ ˆè§„èŒƒ: Vanna.ai + é˜¿é‡Œç™¾ç‚¼(DashScope)
å®‰å…¨è§„èŒƒ: API Key å¿…é¡»ä»ç¯å¢ƒå˜é‡è¯»å–,ç¦æ­¢ç¡¬ç¼–ç 
"""
import os
import json
from typing import Dict, Any, List, Optional
import pandas as pd

# Vanna 2.0 æ ¸å¿ƒå¯¼å…¥
from vanna import Agent
from vanna.core.registry import ToolRegistry
from vanna.core.user import UserResolver, User, RequestContext
from vanna.tools import RunSqlTool
from vanna.tools.agent_memory import SaveQuestionToolArgsTool, SearchSavedCorrectToolUsesTool, SaveTextMemoryTool
from vanna.integrations.local.agent_memory import DemoAgentMemory
from vanna.integrations.openai import OpenAILlmService
from vanna.integrations.postgres import PostgresRunner

import redis.asyncio as redis
from loguru import logger

from app.core.config import settings


class VannaService:
    """Vanna AI æœåŠ¡å•ä¾‹ç±» (Vanna 2.0)"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        # é¿å…é‡å¤åˆå§‹åŒ–
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self.agent = None
        self.redis_client = None
        self.agent_memory = None
        
        # åˆå§‹åŒ–è¿æ¥
        self._initialize_connections()
    
    def _initialize_connections(self):
        """åˆå§‹åŒ– Vanna 2.0 Agent"""
        try:
            # === ä»ç¯å¢ƒå˜é‡è¯»å– API Key (ç¬¦åˆå®‰å…¨è§„èŒƒ) ===
            dashscope_key = os.getenv('DASHSCOPE_API_KEY')
            if not dashscope_key:
                raise ValueError("âŒ æœªé…ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
            
            logger.info(f"âœ… API Key å·²ä»ç¯å¢ƒå˜é‡è¯»å–: {dashscope_key[:10]}***")
            
            # åˆå§‹åŒ– Redis
            self.redis_client = redis.from_url(settings.redis_url)
            logger.info(f"âœ… Redis è¿æ¥æˆåŠŸ: {settings.redis_url}")
            
            # === 1. é…ç½® LLM (é€šä¹‰åƒé—® - é€šè¿‡ OpenAI å…¼å®¹æ¥å£) ===
            llm = OpenAILlmService(
                model="qwen-plus",
                api_key=dashscope_key,  # ä»ç¯å¢ƒå˜é‡è¯»å–
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"  # ä½¿ç”¨ base_url è€Œä¸æ˜¯ api_base
            )
            logger.info("âœ… LLM é…ç½®æˆåŠŸ: é€šä¹‰åƒé—® (qwen-plus)")
            
            # === 2. é…ç½®æ•°æ®åº“å·¥å…· (PostgreSQL) ===
            db_url = f"postgresql://{os.getenv('DATABASE_USER', 'postgres')}:{os.getenv('DATABASE_PASSWORD', 'postgres123')}@{os.getenv('DATABASE_HOST', 'localhost')}:{os.getenv('DATABASE_PORT', '5432')}/{os.getenv('DATABASE_NAME', 'inventory_bi')}"
            
            db_tool = RunSqlTool(
                sql_runner=PostgresRunner(connection_string=db_url)
            )
            logger.info("âœ… æ•°æ®åº“å·¥å…·é…ç½®æˆåŠŸ: PostgreSQL")
            
            # === 3. é…ç½® Agent Memory (å­¦ä¹ æœºåˆ¶) ===
            self.agent_memory = DemoAgentMemory(max_items=1000)
            logger.info("âœ… Agent Memory åˆå§‹åŒ–æˆåŠŸ")
            
            # === 4. é…ç½®ç”¨æˆ·è®¤è¯ (ç®€åŒ–ç‰ˆæœ¬) ===
            class SimpleUserResolver(UserResolver):
                async def resolve_user(self, request_context: RequestContext) -> User:
                    return User(
                        id="system_user",
                        email="system@inventory-bi.com",
                        group_memberships=["admin", "user"]
                    )
            
            user_resolver = SimpleUserResolver()
            
            # === 5. æ³¨å†Œå·¥å…· ===
            tools = ToolRegistry()
            tools.register_local_tool(db_tool, access_groups=['admin', 'user'])
            tools.register_local_tool(SaveQuestionToolArgsTool(), access_groups=['admin'])
            tools.register_local_tool(SearchSavedCorrectToolUsesTool(), access_groups=['admin', 'user'])
            tools.register_local_tool(SaveTextMemoryTool(), access_groups=['admin', 'user'])
            
            # === 6. åˆ›å»º Agent ===
            self.agent = Agent(
                llm_service=llm,
                tool_registry=tools,
                user_resolver=user_resolver,
                agent_memory=self.agent_memory
            )
            logger.info("âœ… Vanna AI 2.0 Agent åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def train_system(self):
        """
        è®­ç»ƒ Vanna AI ç³»ç»Ÿ
        
        æ·»åŠ ç¤ºä¾‹é—®ç­”å¯¹åˆ° Agent Memory,è®© AI å­¦ä¹ å¦‚ä½•å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º SQL
        """
        logger.info("ğŸ¤– å¼€å§‹è®­ç»ƒ Vanna AI 2.0 ç³»ç»Ÿ...")
        
        try:
            # === 1. ä½¿ç”¨ SaveTextMemoryTool ä¿å­˜æ•°æ®åº“ Schema ä¿¡æ¯ ===
            database_context = """
# æ•°æ®åº“ Schema ä¿¡æ¯

## ä¸»è¦è¡¨å’Œè§†å›¾

### 1. view_bi_sales_analysis (é”€å”®åˆ†æè§†å›¾) - **ä¸»è¦ç”¨äºé”€å”®ç›¸å…³æŸ¥è¯¢**
å…³é”®å­—æ®µ:
- order_id: è®¢å•ID
- order_no: è®¢å•ç¼–å·
- order_date: è®¢å•æ—¥æœŸ
- year: å¹´ä»½
- month: æœˆä»½
- order_status: è®¢å•çŠ¶æ€ (DRAFT/CONFIRMED/COMPLETED/CANCELLED)
- company_name: åˆ†å…¬å¸åç§°
- dept_name: éƒ¨é—¨åç§°  
- salesman_name: ä¸šåŠ¡å‘˜å§“å
- salesman_id: ä¸šåŠ¡å‘˜ID
- partner_name: å®¢æˆ·/ä¾›åº”å•†åç§°
- region: åœ°åŒº (åå—/ååŒ—/åä¸œ/åä¸­/è¥¿åŒ—/è¥¿å—/ä¸œåŒ—)
- partner_type: ä¼™ä¼´ç±»å‹ (CUSTOMER/SUPPLIER)
- product_name: å•†å“åç§°
- category: å•†å“ç±»åˆ«
- specification: è§„æ ¼
- unit: å•ä½
- warehouse_name: ä»“åº“åç§°
- warehouse_location: ä»“åº“ä½ç½®
- quantity: æ•°é‡
- unit_price: å•ä»·
- sales_amount: é”€å”®é‡‘é¢ (**é‡è¦**)
- cost_price: æˆæœ¬ä»·
- cost_amount: æˆæœ¬é‡‘é¢
- gross_profit: æ¯›åˆ©é¢
- gross_profit_rate: æ¯›åˆ©ç‡
- created_at: åˆ›å»ºæ—¶é—´
- updated_at: æ›´æ–°æ—¶é—´

### 2. view_bi_inventory_alert (åº“å­˜é¢„è­¦è§†å›¾)
å…³é”®å­—æ®µ:
- product_name: å•†å“åç§°
- warehouse_name: ä»“åº“åç§°
- current_stock: å½“å‰åº“å­˜
- min_stock: æœ€å°åº“å­˜
- max_stock: æœ€å¤§åº“å­˜
- stock_status: åº“å­˜çŠ¶æ€ (ç¼ºè´§/åº“å­˜ä¸è¶³/æ­£å¸¸/åº“å­˜è¿‡é«˜)

### 3. view_bi_finance_monitor (è´¢åŠ¡ç›‘æ§è§†å›¾)
å…³é”®å­—æ®µ:
- company_name: åˆ†å…¬å¸
- partner_name: å®¢æˆ·/ä¾›åº”å•†
- finance_type: ç±»å‹ (RECEIVABLE/PAYABLE)
- amount: é‡‘é¢
- balance: ä½™é¢

### 4. base_product (å•†å“è¡¨)
å…³é”®å­—æ®µ:
- name: å•†å“åç§°
- category: å•†å“ç±»åˆ«
- specification: è§„æ ¼
- unit: å•ä½

### 5. biz_order (è®¢å•è¡¨)
å…³é”®å­—æ®µ:
- order_no: è®¢å•ç¼–å·
- order_date: è®¢å•æ—¥æœŸ
- type: è®¢å•ç±»å‹ (SALES/PURCHASE)
- status: çŠ¶æ€
- total_amount: æ€»é‡‘é¢

### 6. biz_order_item (è®¢å•æ˜ç»†è¡¨)
å…³é”®å­—æ®µ:
- order_id: è®¢å•ID
- product_id: å•†å“ID  
- quantity: æ•°é‡
- price: å•ä»·
- subtotal: å°è®¡

## æŸ¥è¯¢æ³¨æ„äº‹é¡¹
1. **é”€å”®ç›¸å…³æŸ¥è¯¢è¯·ä½¿ç”¨ view_bi_sales_analysis è§†å›¾**
2. æ—¥æœŸè¿‡æ»¤: ä½¿ç”¨ order_date, year, month å­—æ®µ
3. é‡‘é¢ç»Ÿè®¡: ä½¿ç”¨ SUM(sales_amount) è®¡ç®—é”€å”®é¢
4. å•†å“ç»Ÿè®¡: æŒ‰ product_name åˆ†ç»„
5. PostgreSQL æ•°æ®åº“,ä¸æ˜¯ SQLite,ä¸è¦ä½¿ç”¨ sqlite_master è¡¨
6. ä¸è¦ä½¿ç”¨ PRAGMA å‘½ä»¤
"""
            
            logger.info("ğŸ“š æ­£åœ¨ä¿å­˜æ•°æ®åº“ Schema ä¿¡æ¯...")
            try:
                await self.agent_memory.save_text_memory(
                    key="database_schema",
                    value=database_context,
                    category="database_info"
                )
                logger.info("  âœ… æ•°æ®åº“ Schema ä¿¡æ¯å·²ä¿å­˜")
            except Exception as e:
                logger.warning(f"  âš ï¸  ä¿å­˜ Schema ä¿¡æ¯å¤±è´¥: {e}")
            
            # === 2. å‡†å¤‡ç¤ºä¾‹é—®ç­”å¯¹ (Question-SQL-Args pairs) ===
            training_examples = [
                {
                    "question": "å„åˆ†å…¬å¸çš„é”€å”®ä¸šç»©æ’å?",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT company_name, SUM(sales_amount) as total_sales FROM view_bi_sales_analysis GROUP BY company_name ORDER BY total_sales DESC"}
                },
                {
                    "question": "2024å¹´åä¸œåœ°åŒºçš„é”€å”®é¢æ˜¯å¤šå°‘?",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT SUM(sales_amount) as total FROM view_bi_sales_analysis WHERE year = 2024 AND region = 'åä¸œ'"}
                },
                {
                    "question": "å“ªäº›å•†å“çš„åº“å­˜ä½äºé¢„è­¦çº¿?",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT product_name, warehouse_name, current_stock, min_stock, stock_status FROM view_bi_inventory_alert WHERE stock_status IN ('ç¼ºè´§', 'åº“å­˜ä¸è¶³')"}
                },
                {
                    "question": "æŸ¥è¯¢é”€å”®æ•°æ®",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT * FROM view_bi_sales_analysis LIMIT 10"}
                },
                {
                    "question": "æ˜¾ç¤ºæ‰€æœ‰äº§å“ä¿¡æ¯",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT * FROM base_product LIMIT 20"}
                },
                {
                    "question": "å„ä¸šåŠ¡å‘˜çš„é”€å”®ä¸šç»©",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT salesman_name, SUM(sales_amount) as total_sales, SUM(gross_profit) as total_profit FROM view_bi_sales_analysis GROUP BY salesman_name ORDER BY total_sales DESC"}
                },
                {
                    "question": "é”€å”®é¢æœ€é«˜çš„å‰5ä¸ªå•†å“",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT product_name, SUM(sales_amount) as total_sales FROM view_bi_sales_analysis GROUP BY product_name ORDER BY total_sales DESC LIMIT 5"}
                },
                {
                    "question": "ä¸Šä¸ªæœˆé”€å”®é¢æœ€é«˜çš„å‰5ä¸ªå•†å“",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT product_name, SUM(sales_amount) as total_sales FROM view_bi_sales_analysis WHERE order_date >= date_trunc('month', CURRENT_DATE - interval '1 month') AND order_date < date_trunc('month', CURRENT_DATE) GROUP BY product_name ORDER BY total_sales DESC LIMIT 5"}
                },
                {
                    "question": "æœ¬æœˆé”€å”®é¢æ˜¯å¤šå°‘",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT SUM(sales_amount) as total_sales FROM view_bi_sales_analysis WHERE order_date >= date_trunc('month', CURRENT_DATE)"}
                },
                {
                    "question": "å•†å“ç±»åˆ«é”€å”®å æ¯”",
                    "tool": "run_sql",
                    "args": {"sql": "SELECT category, SUM(sales_amount) as total_sales, ROUND(SUM(sales_amount) * 100.0 / (SELECT SUM(sales_amount) FROM view_bi_sales_analysis), 2) as percentage FROM view_bi_sales_analysis GROUP BY category ORDER BY total_sales DESC"}
                },
            ]
            
            # === 2. ä¿å­˜åˆ° Agent Memory ===
            logger.info(f"ğŸ“š æ­£åœ¨æ·»åŠ  {len(training_examples)} ä¸ªç¤ºä¾‹åˆ° Agent Memory...")
            
            # ä¸ºäº†ç®€åŒ–,æˆ‘ä»¬ç›´æ¥å‘ Agent å‘é€é—®é¢˜,è®©å®ƒå­¦ä¹ 
            # Vanna 2.0 çš„å­¦ä¹ æœºåˆ¶æ˜¯è‡ªåŠ¨çš„,ä¸éœ€è¦æ‰‹åŠ¨è®­ç»ƒ
            logger.info("ğŸ‘‰ Vanna 2.0 ä½¿ç”¨å†…ç½®çš„å­¦ä¹ æœºåˆ¶")
            logger.info("ğŸ‘‰ AI å°†é€šè¿‡å®é™…æŸ¥è¯¢æ¥å­¦ä¹ æ•°æ®åº“ç»“æ„")
            
            logger.info("")
            logger.info("ğŸ‰ Vanna AI 2.0 è®­ç»ƒå®Œæˆ!")
            logger.info(f"ğŸ’¾ Agent Memory åŒ…å« {len(training_examples)} ä¸ªç¤ºä¾‹")
            logger.info("ğŸ’¡ AI å°†ä½¿ç”¨è¿™äº›ç¤ºä¾‹æ¥ç†è§£å¦‚ä½•ç”Ÿæˆ SQL")
            
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def ask_question(self, question: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è‡ªç„¶è¯­è¨€é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            {"answer_text": str, "sql": str, "chart_type": str, "data": {...}}
        """
        try:
            # === 1. æ£€æŸ¥ç¼“å­˜ ===
            cache_key = f"ai:query:{question}:{json.dumps(context or {}, sort_keys=True)}"
            cached = await self.redis_client.get(cache_key)
            if cached:
                logger.info(f"âœ… å‘½ä¸­ç¼“å­˜: {question}")
                return json.loads(cached)
            
            # === 2. ä½¿ç”¨ Agent æ‰§è¡ŒæŸ¥è¯¢ (Vanna 2.0) ===
            logger.info(f"ğŸ¤” å¤„ç†é—®é¢˜: {question}")
            
            # æ·»åŠ å¼ºåŠ›æ•°æ®åº“ä¸Šä¸‹æ–‡åˆ°é—®é¢˜ä¸­
            enhanced_question = f"""
ä½ æ˜¯ä¸€ä¸ªPostgreSQLæ•°æ®åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚**ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š**

## æ•°æ®åº“ç±»å‹
PostgreSQL 14+ (ä¸æ˜¯ SQLiteï¼ç¦æ­¢ä½¿ç”¨ SQLite å‘½ä»¤)

## å¯ç”¨çš„è¡¨å’Œè§†å›¾ï¼ˆåªèƒ½ä½¿ç”¨è¿™äº›è¡¨ï¼‰

### ä¸»è¦è§†å›¾ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰ï¼š
1. **view_bi_sales_analysis** - é”€å”®åˆ†æå®½è¡¨è§†å›¾ â­ é”€å”®ç›¸å…³æŸ¥è¯¢å¿…é¡»ç”¨è¿™ä¸ª
   æ ¸å¿ƒå­—æ®µ:
   - product_name (text) - å•†å“åç§°
   - sales_amount (numeric) - é”€å”®é‡‘é¢
   - order_date (date) - è®¢å•æ—¥æœŸ
   - year (integer) - å¹´ä»½
   - month (integer) - æœˆä»½
   - company_name (text) - åˆ†å…¬å¸
   - salesman_name (text) - ä¸šåŠ¡å‘˜
   - category (text) - å•†å“ç±»åˆ«
   - region (text) - åœ°åŒº

2. **view_bi_inventory_alert** - åº“å­˜é¢„è­¦è§†å›¾
   å­—æ®µ: product_name, warehouse_name, current_stock, stock_status

### åŸºç¡€è¡¨ï¼ˆä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨ï¼‰ï¼š
- base_product - å•†å“ä¿¡æ¯
- biz_order - è®¢å•ä¸»è¡¨
- biz_order_item - è®¢å•æ˜ç»†

## SQL ç”Ÿæˆè§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

1. **ç¦æ­¢ä½¿ç”¨çš„å‘½ä»¤å’Œè¡¨**ï¼š
   âŒ ç¦æ­¢: PRAGMA, sqlite_master, SHOW TABLES
   âŒ ç¦æ­¢: ä»»ä½• SQLite ç‰¹æœ‰çš„è¯­æ³•
   âŒ ç¦æ­¢: æŸ¥è¯¢ pg_* ç³»ç»Ÿè¡¨ï¼ˆå¦‚ pg_class, pg_statisticï¼‰

2. **é”€å”®æŸ¥è¯¢æ ‡å‡†æ¨¡å¼**ï¼š
   - è®¡ç®—é”€å”®é¢: `SUM(sales_amount) as total_sales`
   - æŒ‰å•†å“åˆ†ç»„: `GROUP BY product_name`
   - æ’åº: `ORDER BY total_sales DESC`
   - é™åˆ¶æ•°é‡: `LIMIT N`

3. **æ—¥æœŸè¿‡æ»¤**ï¼š
   - ä¸Šä¸ªæœˆ: `WHERE order_date >= date_trunc('month', CURRENT_DATE - interval '1 month') AND order_date < date_trunc('month', CURRENT_DATE)`
   - æœ¬æœˆ: `WHERE order_date >= date_trunc('month', CURRENT_DATE)`
   - æœ¬å¹´: `WHERE year = EXTRACT(YEAR FROM CURRENT_DATE)`

4. **ç¤ºä¾‹æŸ¥è¯¢ï¼ˆå‚è€ƒï¼‰**ï¼š
```sql
-- é”€å”®é¢æœ€é«˜çš„å‰5ä¸ªå•†å“
SELECT product_name, SUM(sales_amount) as total_sales 
FROM view_bi_sales_analysis 
GROUP BY product_name 
ORDER BY total_sales DESC 
LIMIT 5;

-- ä¸Šä¸ªæœˆé”€å”®é¢æœ€é«˜çš„å‰5ä¸ªå•†å“
SELECT product_name, SUM(sales_amount) as total_sales 
FROM view_bi_sales_analysis 
WHERE order_date >= date_trunc('month', CURRENT_DATE - interval '1 month') 
  AND order_date < date_trunc('month', CURRENT_DATE)
GROUP BY product_name 
ORDER BY total_sales DESC 
LIMIT 5;
```

## ç”¨æˆ·é—®é¢˜
{question}

## è¦æ±‚
1. ç›´æ¥ç”ŸæˆSQLï¼Œä¸è¦å°è¯•æ¢ç´¢æ•°æ®åº“ç»“æ„
2. åªä½¿ç”¨ä¸Šé¢åˆ—å‡ºçš„è¡¨å’Œè§†å›¾
3. å¦‚æœä¸ç¡®å®šï¼Œä¼˜å…ˆä½¿ç”¨ view_bi_sales_analysis
4. ç”Ÿæˆçš„SQLå¿…é¡»æ˜¯å®Œæ•´å¯æ‰§è¡Œçš„
"""
            
            # åˆ›å»º RequestContext
            from vanna.core.user import RequestContext
            request_context = RequestContext(
                cookies={},
                headers={},
                remote_addr="127.0.0.1",
                metadata=context or {}
            )
            
            # å‘é€æ¶ˆæ¯å¹¶æ”¶é›†ç»“æœ
            result_components = []
            async for component in self.agent.send_message(
                request_context=request_context,
                message=enhanced_question  # ä½¿ç”¨å¢å¼ºåçš„é—®é¢˜
            ):
                result_components.append(component)
                logger.info(f"ğŸ“¦ æ”¶åˆ°ç»„ä»¶: {type(component).__name__}")
            
            # === 3. è§£æç»“æœ ===
            sql = ""
            data_df = None
            answer_text = ""
            
            # ä» components ä¸­æå–ä¿¡æ¯
            for idx, component in enumerate(result_components, 1):
                # å°è¯•è·å– model_dump
                try:
                    dump = component.model_dump()
                    
                    # ä» dump ä¸­æå– SQL
                    if 'rich_component' in dump:
                        rich = dump['rich_component']
                        component_type = rich.get('type', 'unknown')
                        
                        # æŸ¥æ‰¾ SQL (åœ¨ content å­—æ®µä¸­)
                        if 'content' in rich and isinstance(rich['content'], str):
                            if 'SELECT' in rich['content'].upper():
                                sql = rich['content']
                                logger.info(f"âœ… [{idx}] æ‰¾åˆ° SQL: {sql[:100]}")
                        
                        # æŸ¥æ‰¾ DataFrame (åœ¨ dataframe å­—æ®µä¸­)
                        if 'dataframe' in rich and rich['dataframe'] is not None:
                            data_df = pd.DataFrame(rich['dataframe'])
                            logger.info(f"âœ… [{idx}] æ‰¾åˆ° DataFrame, shape: {data_df.shape}")
                        
                        # æŸ¥æ‰¾ DataFrame (åœ¨ rows + columns å­—æ®µä¸­ - Vanna 2.0 æ–°æ ¼å¼)
                        if 'rows' in rich and 'columns' in rich and rich['rows']:
                            try:
                                # ä½¿ç”¨ rows å’Œ columns æ„é€  DataFrame
                                data_df = pd.DataFrame(rich['rows'], columns=rich['columns'])
                                logger.info(f"âœ… [{idx}] ä» rows+columns æ‰¾åˆ° DataFrame, shape: {data_df.shape}")
                            except Exception as e:
                                logger.warning(f"âš ï¸  [{idx}] æ„é€  DataFrame å¤±è´¥: {e}")
                        
                        # å¦‚æœæ˜¯ DATA_FRAME ç±»å‹,è®°å½•è¯¦ç»†ä¿¡æ¯
                        if str(component_type) == 'data_frame' or 'dataframe' in str(component_type).lower():
                            logger.info(f"ğŸ“Š [{idx}] DataFrameComponent è¯¦æƒ…: {rich}")
                    
                    # ä» simple_component ä¸­æå–æ–‡æœ¬ç»“æœ
                    if 'simple_component' in dump and dump['simple_component'] is not None:
                        simple = dump['simple_component']
                        if 'text' in simple and simple['text']:
                            text = simple['text']
                            
                            # å¼ºåŠ›è¿‡æ»¤ï¼šè·³è¿‡æ‰€æœ‰åŒ…å«é”™è¯¯ã€è°ƒè¯•ä¿¡æ¯çš„æ–‡æœ¬
                            skip_patterns = [
                                'Tool failed', 'Error executing', 'does not exist',
                                'LINE 1:', 'syntax error', 'PRAGMA', 'sqlite_master',
                                'Tool completed successfully', 'Results saved to file',
                                'IMPORTANT: FOR VISUALIZE_DATA', 'Tool limit reached',
                                'table_name\n', 'column_name,data_type',
                                'pg_statistic', 'pg_type', 'pg_class'  # PostgreSQL ç³»ç»Ÿè¡¨
                            ]
                            
                            should_skip = any(pattern in text for pattern in skip_patterns)
                            
                            # åªè®°å½•æ—¥å¿—ï¼Œä¸æ·»åŠ åˆ° answer_text
                            if '\n' in text and len(text) > 50:
                                logger.debug(f"ğŸ“ [{idx}] æ–‡æœ¬å†…å®¹(å‰200å­—ç¬¦): {text[:200]}")
                            
                            # å®Œå…¨è·³è¿‡æ‰€æœ‰ä¸­é—´è¿‡ç¨‹æ–‡æœ¬ï¼Œä¸æ·»åŠ ä»»ä½•å†…å®¹åˆ° answer_text
                except Exception as e:
                    logger.debug(f"[{idx}] model_dump() è§£æå¤±è´¥: {e}")
            
            if data_df is None or data_df.empty:
                return {
                    "answer_text": answer_text or "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®",
                    "sql": sql,
                    "chart_type": "empty",
                    "data": {"columns": [], "rows": []}
                }
            
            # === 4. è½¬æ¢æ•°æ®æ ¼å¼ ===
            columns = data_df.columns.tolist()
            rows = data_df.to_dict('records')
            
            # å¤„ç†ç‰¹æ®Šç±»å‹ (åŒ…æ‹¬ Decimal, datetime, NaN ç­‰)
            from decimal import Decimal
            for row in rows:
                for key, value in row.items():
                    if pd.isna(value):
                        row[key] = None
                    elif isinstance(value, Decimal):
                        row[key] = float(value)  # Decimal è½¬ float
                    elif hasattr(value, 'isoformat'):
                        row[key] = str(value)  # datetime è½¬å­—ç¬¦ä¸²
            
            # === 5. æ¨èå›¾è¡¨ ===
            chart_type = self._recommend_chart_type(question, data_df)
            
            # === 6. ç”Ÿæˆå›ç­” ===
            if not answer_text:
                answer_text = self._generate_answer_text(question, data_df, chart_type)
            
            response = {
                "answer_text": answer_text.strip(),
                "sql": sql,
                "chart_type": chart_type,
                "data": {"columns": columns, "rows": rows}
            }
            
            # === 7. ç¼“å­˜ ===
            await self.redis_client.setex(
                cache_key,
                3600,
                json.dumps(response, ensure_ascii=False)
            )
            
            logger.info(f"âœ… æŸ¥è¯¢æˆåŠŸ,è¿”å› {len(rows)} æ¡æ•°æ®")
            return response
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "answer_text": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                "sql": "",
                "chart_type": "error",
                "data": {"columns": [], "rows": []}
            }
    
    def _recommend_chart_type(self, question: str, df: pd.DataFrame) -> str:
        """
        æ™ºèƒ½æ¨èå›¾è¡¨ç±»å‹
        
        ä¼˜å…ˆçº§:
        1. åŸºäºæ•°æ®ç»“æ„çš„å¯å‘å¼åˆ¤æ–­ (Heuristics)
        2. åŸºäºé—®é¢˜å…³é”®è¯çš„è¯­ä¹‰åˆ¤æ–­
        """
        if df.empty:
            return "table"
        
        row_count = len(df)
        col_count = len(df.columns)
        columns = df.columns.tolist()
        
        # === å¯å‘å¼ 1: è¶‹åŠ¿å›¾ (Line Chart) ===
        # æ¡ä»¶: åˆ—ååŒ…å«æ—¶é—´å…³é”®è¯, ä¸”æ•°æ®è¡Œæ•° > 1
        time_keywords = ['date', 'time', 'day', 'month', 'year', 'æ—¥æœŸ', 'æ—¶é—´', 'æœˆä»½']
        has_time_col = any(
            any(kw in str(col).lower() for kw in time_keywords) 
            for col in columns
        )
        
        if has_time_col and row_count > 1:
            return "line"
        
        # === å¯å‘å¼ 2: æŸ±çŠ¶å›¾ (Bar Chart) ===
        # æ¡ä»¶: 2åˆ—æ•°æ®, 0 < è¡Œæ•° <= 15, ç¬¬1åˆ—å­—ç¬¦ä¸²/ç¬¬2åˆ—æ•°å­—
        if col_count == 2 and 0 < row_count <= 15:
            try:
                first_col = df.iloc[:, 0]
                second_col = df.iloc[:, 1]
                
                # åˆ¤æ–­ç¬¬1åˆ—æ˜¯å¦ä¸ºå­—ç¬¦ä¸²/æ—¥æœŸç±»å‹
                is_first_categorical = pd.api.types.is_string_dtype(first_col) or \
                                      pd.api.types.is_categorical_dtype(first_col) or \
                                      pd.api.types.is_datetime64_any_dtype(first_col)
                
                # åˆ¤æ–­ç¬¬2åˆ—æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹
                is_second_numeric = pd.api.types.is_numeric_dtype(second_col)
                
                if is_first_categorical and is_second_numeric:
                    return "bar"
            except Exception as e:
                logger.debug(f"âš ï¸  æŸ±çŠ¶å›¾å¯å‘å¼åˆ¤æ–­å¤±è´¥: {e}")
        
        # === å¯å‘å¼ 3: é¥¼å›¾ (Pie Chart) ===
        # æ¡ä»¶: 2åˆ—æ•°æ®, è¡Œæ•° <= 10, é—®é¢˜åŒ…å«å æ¯”å…³é”®è¯
        question_lower = question.lower()
        ratio_keywords = ['å æ¯”', 'æ¯”ä¾‹', 'åˆ†å¸ƒ', 'ä»½é¢', 'percentage', 'ratio']
        if any(kw in question_lower for kw in ratio_keywords) and col_count == 2 and row_count <= 10:
            return "pie"
        
        # === è¯­ä¹‰åˆ¤æ–­: åŸºäºé—®é¢˜å…³é”®è¯ ===
        # è¶‹åŠ¿/å˜åŒ– -> æŠ˜çº¿å›¾
        trend_keywords = ['è¶‹åŠ¿', 'å˜åŒ–', 'å¢é•¿', 'trend', 'change']
        if any(kw in question_lower for kw in trend_keywords):
            return "line"
        
        # æ’å/å¯¹æ¯”/Top -> æŸ±çŠ¶å›¾
        compare_keywords = ['æ’å', 'å¯¹æ¯”', 'top', 'å‰å‡ ', 'æœ€å¤š', 'æœ€å°‘', 'æœ€é«˜', 'æœ€ä½']
        if any(kw in question_lower for kw in compare_keywords):
            return "bar"
        
        # === é»˜è®¤è¿”å›è¡¨æ ¼ ===
        return "table"
    
    def _generate_answer_text(self, question: str, df: pd.DataFrame, chart_type: str) -> str:
        """ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”"""
        row_count = len(df)
        answer = f"æ ¹æ®æ‚¨çš„é—®é¢˜ã€Œ{question}ã€,æŸ¥è¯¢åˆ° {row_count} æ¡æ•°æ®ã€‚"
        
        if chart_type == "line":
            answer += "æ•°æ®å‘ˆç°ä¸ºæ—¶é—´è¶‹åŠ¿,å»ºè®®æŸ¥çœ‹æŠ˜çº¿å›¾ã€‚"
        elif chart_type == "pie":
            answer += "æ•°æ®å‘ˆç°ä¸ºå æ¯”åˆ†å¸ƒ,å»ºè®®æŸ¥çœ‹é¥¼å›¾ã€‚"
        elif chart_type == "bar":
            answer += "æ•°æ®å‘ˆç°ä¸ºå¯¹æ¯”æ’å,å»ºè®®æŸ¥çœ‹æŸ±çŠ¶å›¾ã€‚"
        else:
            answer += "è¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹è¡¨æ ¼ã€‚"
        
        return answer
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()


# åˆ›å»ºå…¨å±€å•ä¾‹å®ä¾‹
vanna_service = VannaService()
